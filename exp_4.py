# -*- coding: utf-8 -*-
"""Exp 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NmeraHxLZe81I1thnX_U6Kmpj6-TSOnT
"""

from google.colab import drive
drive.mount('/content/drive')

"""# !Pip istall"""

!pip install nilearn

"""# To check if our model on the Skull stripped pre-processed data can handle Early detection, we will take out the CN, and the EMCI data


From there we will do a binary classification with the same EfficientnetV2S model used earlier. Based on this classification report we can see if the model can see minor changes in brain-tissue and hippocampus and from there distinguish if there are Alzheimer or not
"""

import os
import numpy as np
import nibabel as nib
from nilearn import datasets, image
import matplotlib.pyplot as plt



"""# Take out classes CN and EMCI from the train and augmentation database used in Expiriment 3"""

import pandas as pd

train_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/EXPERIMENT 3/CSV/SPLIT TEST/train_data_rgb.csv')
test_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/EXPERIMENT 3/CSV/SPLIT TEST/test_data_rgb.csv')

train_filtered = train_df[train_df['Class'].isin(['EMCI', 'CN'])]
test_filtered = test_df[test_df['Class'].isin(['EMCI', 'CN'])]

train_filtered.to_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset/train_early_detection.csv', index=False)
test_filtered.to_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset/test_early_detection.csv', index=False)

augmented_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/EXPERIMENT 3/Augmented images/augmented_data.csv')
augmented_filtered = augmented_df[augmented_df['Class'].isin(['EMCI', 'CN'])]
augmented_filtered.to_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset/augmented_early_detection.csv', index=False)

import pandas as pd


train_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/EXPERIMENT 3/Test/train_data.csv')
test_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/EXPERIMENT 3/Test/test_data.csv')
val_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/EXPERIMENT 3/Test/val_data.csv')

# Filter data for specific classes ('EMCI', 'CN')
train_filtered = train_df[train_df['Class'].isin(['EMCI', 'CN'])]
test_filtered = test_df[test_df['Class'].isin(['EMCI', 'CN'])]
val_filtered = val_df[val_df['Class'].isin(['EMCI', 'CN'])]

# Save filtered data to new CSV files
train_filtered.to_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/train_early_detection.csv', index=False)
test_filtered.to_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/test_early_detection.csv', index=False)
val_filtered.to_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/val_early_detection.csv', index=False)

augmented_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/EXPERIMENT 3/Test/augmented_data.csv')

augmented_filtered = augmented_df[augmented_df['Class'].isin(['EMCI', 'CN'])]

# Save filtered augmented data to new CSV file
augmented_filtered.to_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/augmented_early_detection.csv', index=False)

print("All datasets have been processed and saved.")

"""#Binary Classification using CN and EMCI (Healthy, and Alzheimer)"""

import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential, layers
from tensorflow.keras.applications import EfficientNetV2S
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

augmented_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/augmented_early_detection.csv')
train_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/train_early_detection.csv')
val_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/val_early_detection.csv')
test_df = pd.read_csv('/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/EXPERIMENT/Early detection (Exp 4)/Dataset new/test_early_detection.csv')

combined_train_data = pd.concat([train_df, augmented_df])

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(
    dataframe=combined_train_data,
    x_col='image_path',
    y_col='Class',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    x_col='image_path',
    y_col='Class',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    x_col='image_path',
    y_col='Class',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

# Load EfficientNetV2S pre-trained on ImageNet
base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Define the custom model
custom_model = Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.5),
    layers.Flatten(),
    layers.Dropout(0.3),
    layers.Dense(128, activation='elu'),
    layers.Dense(1, activation='sigmoid')  # Binary classification with sigmoid
])

# Compile the model
custom_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

# Training parameters
epochs = 50
early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)

# Train the model
history = custom_model.fit(
    train_generator,
    epochs=epochs,
    validation_data=val_generator,
    callbacks=[early_stopping]
)

# Plot accuracy and loss
plt.figure(figsize=(12, 4))

# Accuracy graph
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss graph
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

y_pred_proba = custom_model.predict(test_generator).ravel()  # Make sure predictions are flattened

# Get true labels from the generator
y_true = test_generator.classes

# Binarize predictions based on the threshold
y_pred = (y_pred_proba > 0.5).astype(int)

# Classification report
print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))

# ROC Curve
fpr, tpr, _ = roc_curve(y_true, y_pred_proba)
roc_auc = auc(fpr, tpr)

# Plot ROC Curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)
average_precision = average_precision_score(y_true, y_pred_proba)

# Plot Precision-Recall Curve
plt.figure()
plt.step(recall, precision, where='post', color='b', alpha=0.2,
         label='Precision-Recall curve (AP = {0:0.2f})'.format(average_precision))
plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall curve')
plt.legend(loc='lower left')
plt.show()



!nvidia-smi

!lscpu |grep 'Model name'

