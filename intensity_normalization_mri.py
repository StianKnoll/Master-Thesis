# -*- coding: utf-8 -*-
"""Intensity normalization MRI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1REzJGeLS3l-i3p2qaOuPb1Qwbm0x9Vwn

## **Intensity Normalization using Histogram normalization for exp. 2, 3 & 4**
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install nibabel

## Import libaries

import os
import numpy as np
import nibabel as nib

"""**Normal brain (without SS): Structuring the dataset into batches and creating averages**






"""

def create_average_image_from_files(base_folder, output_folder, file_suffix, batch_size):
    batch_averages = []
    file_paths = []

    print("Starting to traverse the directories for " + file_suffix)
    # Walk through the directory structure and collect all relevant file paths
    for root, dirs, files in os.walk(base_folder):
        # Diagnostic print to show the current directory being checked
        print(f"Currently checking directory: {root}")
        for file in files:
            # Diagnostic print to show all files in the current directory
            print(f"Found file: {file}")
            if file.endswith(file_suffix):
                # Confirmation that a file matching the criteria was found
                print(f"Matched file with criteria '{file_suffix}': {file}")
                file_paths.append(os.path.join(root, file))

    # Ensure there are files to process
    if not file_paths:
        print("No files found that match the criteria. Exiting.")
        return None

    # Process files in batches of 'batch_size'
    print(f"Processing files in batches of {batch_size}.")
    for i in range(0, len(file_paths), batch_size):
        batch_files = file_paths[i:i + batch_size]
        print(f"Processing batch {i // batch_size + 1} with {len(batch_files)} files.")
        batch_images = [nib.load(f).get_fdata() for f in batch_files]
        batch_average = np.mean(batch_images, axis=0)
        batch_averages.append(batch_average)

    # Calculate the final average from all batch averages
    print("Calculating the final average from batch averages.")
    final_average_data = np.mean(batch_averages, axis=0)
    reference_image = nib.Nifti1Image(final_average_data, affine=nib.load(file_paths[0]).affine)

    # Save the final average image
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    final_average_image_path = os.path.join(output_folder, f'final_averaged_frame.{file_suffix}')
    nib.save(reference_image, final_average_image_path)
    print(f"Final average image saved at: {final_average_image_path}")

    return final_average_image_path

# Database setup for original brain files
base_folder_orig = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/!THESIS! GAUSSIAN SMOOTHING'
output_folder_orig = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/Averaged frames for intensity normalization/Normal'
file_suffix_orig = 'orig.nii'
batch_size_orig = 20

average_reference_path_orig = create_average_image_from_files(base_folder_orig, output_folder_orig, file_suffix_orig, batch_size_orig)

if average_reference_path_orig:
    print("Process completed successfully for original brain files.")
else:
    print("Process failed or no original brain images met the criteria.")

"""**Normal brain (without SS): Performing Histogram normalization**



"""

from skimage.exposure import match_histograms

def find_nifti_files(base_folder, file_suffix):
    """Walk through the directory structure and find all NIFTI files matching the suffix."""
    nifti_files = []
    for root, dirs, files in os.walk(base_folder):
        for file in files:
            if file.endswith(file_suffix):
                nifti_files.append(os.path.join(root, file))
    return nifti_files

def perform_histogram_normalization(reference_image_path, nifti_files, output_folder):
    """Perform histogram normalization for each NIFTI file against a reference image."""
    # Load the reference image for histogram matching
    reference_image = nib.load(reference_image_path).get_fdata()

    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Normalize each image in the nifti_files
    for file_path in nifti_files:
        # Load the target image
        target_image = nib.load(file_path).get_fdata()
        # Perform histogram matching
        matched_image = match_histograms(target_image, reference_image, multichannel=False)

        # Prepare the output path preserving the original directory structure
        relative_path = os.path.relpath(file_path, start=base_folder)
        normalized_image_output_path = os.path.join(output_folder, relative_path)
        os.makedirs(os.path.dirname(normalized_image_output_path), exist_ok=True)

        # Save the matched image
        matched_image_nifti = nib.Nifti1Image(matched_image.astype(np.float32), affine=nib.load(file_path).affine)
        nib.save(matched_image_nifti, normalized_image_output_path)
        print(f"Normalized image saved at: {normalized_image_output_path}")


base_folder = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/!THESIS! GAUSSIAN SMOOTHING'
output_folder = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/!THESIS! INT. NORM. (NO SS)'
file_suffix = 'orig.nii'
reference_image_path = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/Averaged frames for intensity normalization/Normal/final_averaged_frame.orig.nii'

# Step 1: Find all NIFTI files in the directory structure
nifti_files = find_nifti_files(base_folder, file_suffix)

# Step 2: Perform histogram normalization on each found file
perform_histogram_normalization(reference_image_path, nifti_files, output_folder)

"""**Skull-stripped brain: Structuring the dataset into batches and creating averages**"""

def create_average_image_from_folders(base_folder, output_folder, file_suffix, batch_size):
    batch_averages = []
    file_paths = []

    print("Starting to traverse the directories.")
    # Walk through the directory structure and collect all relevant file paths
    for root, dirs, files in os.walk(base_folder):
        # Diagnostic print to show the current directory being checked
        print(f"Currently checking directory: {root}")
        for file in files:
            # Diagnostic print to show all files in the current directory
            print(f"Found file: {file}")
            if file.endswith(file_suffix):
                # Confirmation that a file matching the criteria was found
                print(f"Matched file with criteria '{file_suffix}': {file}")
                file_paths.append(os.path.join(root, file))

    # Ensure there are files to process
    if not file_paths:
        print("No files found that match the criteria. Exiting.")
        return None

    # Process files in batches of 'batch_size'
    print(f"Processing files in batches of {batch_size}.")
    for i in range(0, len(file_paths), batch_size):
        batch_files = file_paths[i:i + batch_size]
        print(f"Processing batch {i // batch_size + 1} with {len(batch_files)} files.")
        batch_images = [nib.load(f).get_fdata() for f in batch_files]
        batch_average = np.mean(batch_images, axis=0)
        batch_averages.append(batch_average)

    # Calculate the final average from all batch averages
    print("Calculating the final average from batch averages.")
    final_average_data = np.mean(batch_averages, axis=0)
    reference_image = nib.Nifti1Image(final_average_data, affine=nib.load(file_paths[0]).affine)

    # Save the final average image
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    final_average_image_path = os.path.join(output_folder, 'final_averaged_frame.brainmask.nii')
    nib.save(reference_image, final_average_image_path)
    print(f"Final average image saved at: {final_average_image_path}")

    return final_average_image_path

# Database setup
base_folder = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/!THESIS! - (after "recon-all" and .mgz --> .nii)'
output_folder = '/content/drive/MyDrive/MASTER THESIS/Code and modelling/Database/Averaged frames for intensity normalization/Brainmask'
file_suffix = 'brainmask.nii'
batch_size = 20

average_reference_path = create_average_image_from_folders(base_folder, output_folder, file_suffix, batch_size)

if average_reference_path:
    print("Process completed successfully.")
else:
    print("Process failed or no images met the criteria.")

"""**Skull-stripped brain: Performing Histogram normalization**

"""

from skimage.exposure import match_histograms

def find_nifti_files(base_folder, file_suffix):
    """Walk through the directory structure and find all NIFTI files matching the suffix."""
    nifti_files = []
    for root, dirs, files in os.walk(base_folder):
        for file in files:
            if file.endswith(file_suffix):
                nifti_files.append(os.path.join(root, file))
    return nifti_files

def perform_histogram_normalization(reference_image_path, nifti_files, output_folder):
    """Perform histogram normalization for each NIFTI file against a reference image."""
    # Load the reference image for histogram matching
    reference_image = nib.load(reference_image_path).get_fdata()

    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Normalize each image in the nifti_files
    for file_path in nifti_files:
        # Load the target image
        target_image = nib.load(file_path).get_fdata()
        # Perform histogram matching
        matched_image = match_histograms(target_image, reference_image, multichannel=False)

        # Prepare the output path preserving the original directory structure
        relative_path = os.path.relpath(file_path, start=base_folder)
        normalized_image_output_path = os.path.join(output_folder, relative_path)
        os.makedirs(os.path.dirname(normalized_image_output_path), exist_ok=True)

        # Save the matched image
        matched_image_nifti = nib.Nifti1Image(matched_image.astype(np.float32), affine=nib.load(file_path).affine)
        nib.save(matched_image_nifti, normalized_image_output_path)
        print(f"Normalized image saved at: {normalized_image_output_path}")

base_folder = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/!THESIS! - (after "recon-all" and .mgz --> .nii)'
output_folder = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/!THESIS! NORMALIZED BRAIN MASK'
file_suffix = 'brainmask.nii'
reference_image_path = '/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/Averaged frames for intensity normalization/Brainmask/final_averaged_frame.brainmask.nii'
# Step 1: Find all NIFTI files in the directory structure
nifti_files = find_nifti_files(base_folder, file_suffix)

# Step 2: Perform histogram normalization on each found file
perform_histogram_normalization(reference_image_path, nifti_files, output_folder)

import nibabel as nib

# Replace with the actual path to your Nifti file, using double quotes
nifti_file_path = "/content/drive/MyDrive/MASTER THESIS/CODE & MODELLING/DATABASE/!THESIS! GAUSSIAN SMOOTHING/AD/003_S_6833/003_S_6833_orig.nii"

# Load the Nifti file
nifti_img = nib.load(nifti_file_path)

# Get the header information
header = nifti_img.header

# Print the header information
print(header)

